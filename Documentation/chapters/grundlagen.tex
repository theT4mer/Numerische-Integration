\section{Statistische Grundlagen}
\label{sec:statistische_grundlagen}

\subsection{Normalverteilung}
\label{sec:normal_distribution}
Die Gaußsche Normalverteilung beschreibt die Verteilung einer stetigen Zufallsvariablen und ist durch zwei Parameter, den Mittelwert $\mu$ und die Standardabweichung $\sigma$, charakterisiert. Sie wird aufgrund ihrer Form auch als \textit{Glockenkurve} (s. \autoref{fig:normaldistribution}) bezeichnet und ist symmetrisch um den Mittelwert.
\begin{figure}[h]
    \centering
    \includegraphics[width=8cm]{Bilder/normal_distribution.png}
    \caption{
        Auswahl verschiedener normalverteilten Funktionen \cite{normaldistribution}}    
    \label{fig:normaldistribution}
\end{figure}
\subsection*{Wichtige Eigenschaften}
\begin{itemize}
    \item Die Dichtefunktion der Normalverteilung lautet:
    \[
    \varphi(u) = \frac{1}{\sqrt{2 \pi}} \cdot \exp\left( -\frac{1}{2} \cdot u^2 \right) \quad (-\infty < u < \infty)
    \]
    \item Die Verteilungsfunktion ist gegeben durch:
    \[
    \Phi(u) = P(U \leq u) = \frac{1}{\sqrt{2 \pi}} \cdot \int_{-\infty}^{\infty} \exp\left( -\frac{1}{2} \cdot t^2 \right) \, dt
    \]
    \item Die Normalverteilung ist symmetrisch zum Mittelwert $\mu$, hat ein Maximum bei $x = \mu$ und Wendepunkte bei $x = \mu \pm \sigma$.
    \item Sie ist normiert, d.h., das Integral über die gesamte Dichtefunktion ergibt 1:
    \[
    \int_{-\infty}^{\infty} f(x) \, dx = 1
    \]
\end{itemize}

\subsection*{Berechnung der Wahrscheinlichkeiten}
Für die Berechnung von Wahrscheinlichkeiten, die der Gaußschen Normalverteilung folgen, werden in der Praxis oft Tabellen oder eben numerische Verfahren verwendet, da die Integrale analytisch nicht lösbar sind (deswegen machen wir ja den ganzen Spaß mit der Trapezregel). Die Wahrscheinlichkeit für einen Bereich $a \leq X \leq b$ kann mit der Verteilungsfunktion berechnet werden:
\[
P(a \leq X \leq b) = \Phi\left(\frac{b - \mu}{\sigma}\right) - \Phi\left(\frac{a - \mu}{\sigma}\right)
\]

\subsection*{Wahrscheinlichkeiten in Abhängigkeit der Standardabweichung}

Da die Normalverteilung symmetrisch um den Mittelwert $\mu$ ist, lassen sich bestimmte Wahrscheinlichkeitsbereiche in Abhängigkeit von der Standardabweichung $\sigma$ um $\mu$ angeben:

\begin{itemize}
    \item Etwa 68,27\% aller Werte einer normalverteilten Zufallsvariablen liegen im Intervall $[\mu - \sigma, \mu + \sigma]$, also innerhalb einer Standardabweichung um den Mittelwert.
    \item Etwa 95,45\% der Werte befinden sich im Intervall $[\mu - 2\sigma, \mu + 2\sigma]$, also innerhalb von zwei Standardabweichungen.
    \item Rund 99,73\% der Werte liegen im Intervall $[\mu - 3\sigma, \mu + 3\sigma]$, also innerhalb von drei Standardabweichungen.
\end{itemize}
Diese Bereiche werden auch als \textit{Empirische Regel} oder \textit{68-95-99,7-Regel} bezeichnet und sind besonders nützlich zur Einschätzung, wie wahrscheinlich es ist, dass eine Zufallsvariable in einem bestimmten Bereich um den Mittelwert liegt. Die Wahrscheinlichkeit, dass ein Wert weiter als $3\sigma$ vom Mittelwert entfernt liegt, ist sehr gering und beträgt nur ca. 0,27\%. \\
In der Praxis wird die Normalverteilung zur Modellierung vieler realer Phänomene verwendet, wie z.B. Fehlerverteilungen, Körpergrößen oder Filteralgorithmen (z.B. Kalman Filter/EKF), da viele natürliche Prozesse einem normalverteilten Muster folgen. \cite{skript_statistik} \cite{normaldistribution}


\subsection{Standardnormalverteilung}
\label{sec:standard_normal_distribution}

Eine Normalverteilung lässt sich durch die Standardisierung mit $z = \frac{x - \mu}{\sigma}$ auf die sogenannte Standardnormalverteilung $\mathcal{N}(0, 1)$ zurückführen, die Mittelwert 0 und Standardabweichung 1 hat:
\[
\varphi(z) = \frac{1}{\sqrt{2 \pi}} \cdot \exp\left(-\frac{z^2}{2}\right)
\]
Verteilungsfunktion:
\[
\phi(z) = P(U \leq u) = \frac{1}{\sqrt{2 \pi}} \cdot \int_{-\infty}^{\infty} \exp\left(-\frac{t^2}{2}\right)\, dt
\]
Die Standardnormalverteilung ist ein nützliches Werkzeug in der Statistik, da sie es ermöglicht, beliebige Normalverteilungen durch eine Transformation auf diese Standardform zu bringen. Dies wird durch die Berechnung des \textit{z-Scores} erreicht:
\[
z = \frac{X - \mu}{\sigma}
\]
Der z-Wert gibt an, wie viele Standardabweichungen ein Wert \(X\) vom Mittelwert entfernt ist. Diese Transformation erleichtert die Berechnung von Wahrscheinlichkeiten und statistischen Tests, da die Eigenschaften der Standardnormalverteilung bekannt sind und in Tabellen dokumentiert werden.
Die Standardnormalverteilung ist also quasi eine Normalverteilung wo der Hochpunnkt bei $x=0$ liegt

\subsection{t-Student-Verteilung}
\label{sec:t_student_distribution}
\begin{figure}[h]
    \centering
    \includegraphics[width=8cm]{Bilder/t-Studentenverteilung.png}
    \caption{
        Dichten von t-verteilten Zufallsgrößen \cite{studenten_t_verteilung}}    
    \label{fig:t-verteilung}
\end{figure}
Die standardisierte Schätzfunktion des Stichprobenmittelwerts normalverteilter Daten ist nicht mehr normalverteilt, sondern \(t\)-verteilt, wenn die zur Standardisierung des Mittelwerts benötigte Varianz des Merkmals unbekannt ist und mit der Stichprobenvarianz geschätzt werden muss. Seine \(t\)-Verteilung ermöglicht die Berechnung der Verteilung der Differenz zwischen dem Mittelwert der Stichprobe und dem wahren Mittelwert der Grundgesamtheit. \\
Die \(t\)-Werte hängen vom Signifikanzniveau sowie von der Stichprobengröße \(n\) ab und bestimmen das Vertrauensintervall sowie die Aussagekraft der Schätzung des Mittelwertes. Die \(t\)-Verteilung wird mit wachsendem \(n\) schmaler und konvergiert für \(n \to \infty\) zur Standardnormalverteilung. Hypothesentests, bei denen die \(t\)-Verteilung Verwendung findet, bezeichnet man als \(t\)-Tests. \cite{studenten_t_verteilung}\\
Die t-Student-Verteilung wird verwendet, wenn die Stichprobengröße klein ist (\(n < 30\)) und die Varianz der Grundgesamtheit unbekannt ist. Sie ähnelt der Normalverteilung (s. \autoref{fig:t-verteilung}), hat jedoch „schwerere“ Ränder. Dies bedeutet, dass extremere Werte wahrscheinlicher sind als bei der Normalverteilung.
Die t-Student-Verteilung hat einen Parameter, die Freiheitsgrade \(df\), der die Form der Verteilung bestimmt. Je größer die Freiheitsgrade, desto mehr nähert sich die t-Verteilung der Normalverteilung an. Bei einer großen Stichprobengröße (ca. \(df > 30\)) ist der Unterschied zur Normalverteilung vernachlässigbar.
In der Statistik wird die t-Verteilung häufig für Hypothesentests verwendet. Sie spielt auch bei der Berechnung von Konfidenzintervallen eine wichtige Rolle, wenn die Varianz der Grundgesamtheit nicht bekannt ist.


\subsection{$\chi^2$-Verteilung}
\label{sec:chi_square_distribution}
\begin{figure}[h]
    \centering
    \includegraphics[width=8cm]{Bilder/chi^2-distribution.png}
    \caption{
        Weitere Einzelheiten
        Dichten der Chi-Quadrat-Verteilung mit unterschiedlicher Anzahl an Freiheitsgraden k \cite{chi^2_distribution}}    
    \label{fig:keplersche_fassregel}
\end{figure}
Die \textbf{$\chi^2$-Verteilung} entsteht als Summe der quadrierten z-Werte aus einer Standardnormalverteilung. Sie wird häufig in der Statistik verwendet, um Varianzen zu schätzen und in Hypothesentests wie dem \textit{Chi²-Anpassungstest} oder dem \textit{Chi²-Test zur Unabhängigkeit}.
Die Chi²-Verteilung hat einen Parameter, die Freiheitsgrade \(df\), der die Form der Verteilung bestimmt. Sie ist asymmetrisch und nur für positive Werte definiert. Für \(df \geq 30\) nähert sich die Chi²-Verteilung zunehmend der Normalverteilung an.
Ein häufiges Anwendungsgebiet der Chi²-Verteilung ist die Analyse von Kontingenztafeln, bei denen überprüft wird, ob zwei kategorische Variablen unabhängig voneinander sind.
